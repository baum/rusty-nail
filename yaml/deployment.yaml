---
# Scoped service account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: noobaa-source-controller
  namespace: default
automountServiceAccountToken: true

---
# Access for the service account
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: control-noobaa-sources
rules:
  - apiGroups: ["knative.dev"]
    resources: ["noobaasources", "noobaasources/status"]
    verbs:
    - get
    - watch
    - list
    - patch
  - apiGroups: ["events.k8s.io"]
    resources: ["events"]
    verbs: ["create"]

---
# Binding the role to the account in default
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: noobaa-source-controller-binding
subjects:
- kind: ServiceAccount
  namespace: default
  name: noobaa-source-controller
roleRef:
  kind: ClusterRole
  name: control-noobaa-sources
  apiGroup: rbac.authorization.k8s.io

---
# Expose the http port of the service
apiVersion: v1
kind: Service
metadata:
  name: noobaa-source-controller
  namespace: default
  labels:
    app: noobaa-source-controller
spec:
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  selector:
    app: noobaa-source-controller

---
# Main deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: noobaa-source-controller
  namespace: default
  labels:
    app: noobaa-source-controller
spec:
  replicas: 1
  selector:
    matchLabels:
      app: noobaa-source-controller
  template:
    metadata:
      labels:
        app: noobaa-source-controller
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
    spec:
      serviceAccountName: noobaa-source-controller
      containers:
      - name: noobaa-source-controller
        image: quay.io/baum/rusty-nail
        #command: ["tail"]
        #args: ["-f", "/dev/null"]
        command: ["/app/controller"]
        imagePullPolicy: Always
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 50m
            memory: 100Mi
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        env:
        # We are pointing to tempo or grafana tracing agent's otlp grpc receiver port
        - name: OPENTELEMETRY_ENDPOINT_URL
          value: "https://promstack-tempo.monitoring.svc.cluster.local:4317"
        - name: RUST_LOG
          value: trace
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
